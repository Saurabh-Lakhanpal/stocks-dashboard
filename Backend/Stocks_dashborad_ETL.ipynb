{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle pandas sqlalchemy psycopg2-binary yfinance pandas_datareader requests beautifulsoup4 matplotlib Pillow flask_cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import requests\n",
    "import psycopg2\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "from psycopg2 import sql\n",
    "import shutil\n",
    "import stat\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 619029 entries, 0 to 619039\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   date         619029 non-null  object \n",
      " 1   open_price   619029 non-null  float64\n",
      " 2   high         619029 non-null  float64\n",
      " 3   low_price    619029 non-null  float64\n",
      " 4   close_price  619029 non-null  float64\n",
      " 5   volume       619029 non-null  int64  \n",
      " 6   ticker       619029 non-null  object \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 37.8+ MB\n",
      "==================================================================================\n",
      "Missing tickers in ticker_tb: ['AAL' 'AAP' 'ABC' 'ADS' 'AET' 'AGN' 'AIV' 'ALK' 'ALXN' 'AMG' 'ANDV'\n",
      " 'ANTM' 'APC' 'ARNC' 'ATVI' 'AYI' 'BBT' 'BHF' 'BHGE' 'BLL' 'CA' 'CBG'\n",
      " 'CBS' 'CELG' 'CERN' 'CHK' 'CMA' 'COG' 'COL' 'COTY' 'CSRA' 'CTL' 'CTXS'\n",
      " 'CXO' 'DISCA' 'DISCK' 'DISH' 'DPS' 'DRE' 'DWDP' 'DXC' 'ESRX' 'ETFC'\n",
      " 'EVHC' 'FBHS' 'FB' 'FISV' 'FLIR' 'FLR' 'FLS' 'FL' 'FTI' 'GGP' 'GPS' 'GT'\n",
      " 'HBI' 'HCN' 'HCP' 'HOG' 'HP' 'HRB' 'HRS' 'ILMN' 'INFO' 'JEC' 'JWN' 'KORS'\n",
      " 'KSS' 'KSU' 'LB' 'LEG' 'LLL' 'LNC' 'LUK' 'MAC' 'MAT' 'MON' 'MRO' 'MYL'\n",
      " 'M' 'NAVI' 'NBL' 'NFX' 'NLSN' 'NOV' 'NWL' 'PBCT' 'PCLN' 'PDCO' 'PKI'\n",
      " 'PRGO' 'PVH' 'PXD' 'PX' 'QRVO' 'RE' 'RHI' 'RHT' 'RRC' 'RTN' 'SCG' 'SEE'\n",
      " 'SIG' 'SLG' 'SNI' 'SRCL' 'STI' 'SYMC' 'TIF' 'TMK' 'TRIP' 'TSS' 'TWX'\n",
      " 'UAA' 'UA' 'UNM' 'UTX' 'VAR' 'VFC' 'VIAB' 'VNO' 'WHR' 'WLTW' 'WRK' 'WU'\n",
      " 'WYN' 'XEC' 'XLNX' 'XL' 'XRAY' 'XRX' 'ZION']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   ticker        503 non-null    object\n",
      " 1   company_name  503 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.0+ KB\n",
      "==================================================================================\n",
      "Database stocks_dashboard_db dropped successfully.\n",
      "Database stocks_dashboard_db created successfully.\n",
      "SQL schema file executed successfully.\n",
      "Data for ticker_tb uploaded successfully. Total rows: 503\n",
      "Data for sp500_tb uploaded successfully. Total rows: 619029\n",
      "Data for portfolio_tb uploaded successfully. Total rows: 6\n"
     ]
    }
   ],
   "source": [
    "# Set the Kaggle configuration directory to a custom path\n",
    "custom_kaggle_path = '.kaggle'\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = custom_kaggle_path\n",
    "\n",
    "# Define paths\n",
    "zip_file_path = 'Resources/sandp500.zip'\n",
    "extract_path = 'Resources/sandp500'\n",
    "\n",
    "# Function to handle permission errors\n",
    "def handle_remove_readonly(func, path, exc_info):\n",
    "    os.chmod(path, stat.S_IWRITE)\n",
    "    func(path)\n",
    "\n",
    "# Remove existing ZIP file if it exists\n",
    "if os.path.exists(zip_file_path):\n",
    "    os.remove(zip_file_path)\n",
    "\n",
    "# Remove existing folder and its contents if it exists\n",
    "if os.path.exists(extract_path):\n",
    "    shutil.rmtree(extract_path, onerror=handle_remove_readonly)\n",
    "\n",
    "# Download the S&P 500 dataset from Kaggle and store in the Resources folder\n",
    "os.system('kaggle datasets download -d camnugent/sandp500 -p Resources')\n",
    "\n",
    "# Unzip the downloaded file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# Load dataset into DataFrame\n",
    "csv_file_path = os.path.join(extract_path, 'all_stocks_5yr.csv')\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Delete the ZIP file and extracted folder after loading the dataset\n",
    "os.remove(zip_file_path)\n",
    "shutil.rmtree(extract_path, onerror=handle_remove_readonly)\n",
    "\n",
    "# Remove rows with missing values\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "# Convert date column to datetime using .loc\n",
    "cleaned_df.loc[:, 'date'] = pd.to_datetime(cleaned_df['date'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates (NaT values)\n",
    "cleaned_df = cleaned_df.dropna(subset=['date'])\n",
    "\n",
    "# Rename columns for clarity using .loc\n",
    "cleaned_df = cleaned_df.rename(columns={'Name': 'ticker', 'date': 'date', 'open': 'open_price', \n",
    "                                        'close': 'close_price', 'low': 'low_price', 'high_price': 'high_price', \n",
    "                                        'volume': 'volume'})\n",
    "\n",
    "# Convert date column back to datetime to ensure correct format for PostgreSQL\n",
    "cleaned_df.loc[:, 'date'] = pd.to_datetime(cleaned_df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Display df info\n",
    "cleaned_df.info()\n",
    "print('==================================================================================')\n",
    "\n",
    "# Fetch S&P 500 tickers from Wikipedia\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Request page content with headers to avoid being blocked\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tables = soup.find_all('table', {'class': 'wikitable'}) \n",
    "    \n",
    "    if len(tables) > 0:\n",
    "        table = tables[0]\n",
    "        \n",
    "        # Wrap the table HTML string in a StringIO object\n",
    "        table_html = StringIO(str(table))\n",
    "        \n",
    "        # Read the table directly into a DataFrame using pandas\n",
    "        ticker_df = pd.read_html(table_html)[0]\n",
    "        \n",
    "        # Select only the Ticker Symbol and Company Name columns\n",
    "        ticker_df = ticker_df[['Symbol', 'Security']]\n",
    "        \n",
    "        # Rename columns for clarity\n",
    "        ticker_df.columns = ['ticker', 'company_name']\n",
    "        \n",
    "        # Check for duplicates and drop them\n",
    "        ticker_df = ticker_df.drop_duplicates()\n",
    "\n",
    "        # Check for missing/null values and drop rows with any missing values\n",
    "        ticker_df = ticker_df.dropna()\n",
    "\n",
    "        # Verify that all tickers in cleaned_df are present in ticker_df\n",
    "        missing_tickers = cleaned_df[~cleaned_df['ticker'].isin(ticker_df['ticker'])]['ticker'].unique()\n",
    "        if len(missing_tickers) > 0:\n",
    "            print(f\"Missing tickers in ticker_tb: {missing_tickers}\")\n",
    "\n",
    "        # Display DataFrame info after cleaning\n",
    "        ticker_df.info()\n",
    "    else:\n",
    "        print(\"Error: S&P 500 company table not found on Wikipedia.\")\n",
    "else:\n",
    "    print(f\"Error: Failed to fetch page, status code {response.status_code}\")\n",
    "print('==================================================================================')\n",
    "\n",
    "# Define initial and target database parameters\n",
    "initial_db_params = {\n",
    "    'dbname': 'postgres',  \n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "db_params = {\n",
    "    'dbname': 'stocks_dashboard_db',  \n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "# Functions for database operations\n",
    "def terminate_sessions(cursor, dbname):\n",
    "    cursor.execute(sql.SQL(\"\"\"\n",
    "        SELECT pg_terminate_backend(pid)\n",
    "        FROM pg_stat_activity\n",
    "        WHERE datname = %s AND pid <> pg_backend_pid();\n",
    "    \"\"\"), [dbname])\n",
    "\n",
    "def drop_database(cursor, dbname):\n",
    "    cursor.execute(\"SELECT pg_terminate_backend(pg_stat_activity.pid) FROM pg_stat_activity WHERE pg_stat_activity.datname = %s AND pid <> pg_backend_pid();\", [dbname])\n",
    "    cursor.execute(sql.SQL(\"DROP DATABASE IF EXISTS {}\").format(sql.Identifier(dbname)))\n",
    "\n",
    "def create_database(cursor, dbname):\n",
    "    cursor.execute(sql.SQL(\"CREATE DATABASE {}\").format(sql.Identifier(dbname)))\n",
    "\n",
    "def execute_sql_file(cursor, sql_file_path):\n",
    "    with open(sql_file_path, 'r') as file:\n",
    "        sql_commands = file.read()\n",
    "    cursor.execute(sql.SQL(sql_commands))\n",
    "\n",
    "sql_file_path = 'stocks_dashboard_db_schema.sql'\n",
    "\n",
    "# Connect to the initial database and create the target database\n",
    "try:\n",
    "    # Connect to the initial database (postgres)\n",
    "    connection = psycopg2.connect(**initial_db_params)\n",
    "    connection.autocommit = True\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Drop the target database if it exists\n",
    "    drop_database(cursor, db_params['dbname'])\n",
    "    print(f\"Database {db_params['dbname']} dropped successfully.\")\n",
    "\n",
    "    # Create the target database\n",
    "    create_database(cursor, db_params['dbname'])\n",
    "    print(f\"Database {db_params['dbname']} created successfully.\")\n",
    "\n",
    "    # Close the initial connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    # Connect to the newly created target database (stocks_dashboard_db)\n",
    "    connection = psycopg2.connect(**db_params)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Execute the SQL schema file to set up the database\n",
    "    execute_sql_file(cursor, sql_file_path)\n",
    "    connection.commit()\n",
    "    print(\"SQL schema file executed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    if connection:\n",
    "        connection.rollback()\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "\n",
    "# Upload data from DataFrames to PostgreSQL\n",
    "def upload_df_to_table(connection_string, table_name, df):\n",
    "    engine = create_engine(connection_string)\n",
    "    df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "    return len(df)\n",
    "\n",
    "# Ensure column names in cleaned_df and ticker_df match the table schema\n",
    "ticker_df.columns = ['ticker', 'company_name']\n",
    "cleaned_df.columns = ['date', 'open_price', 'close_price', 'low_price', 'high_price', 'volume', 'ticker']\n",
    "\n",
    "# Upload the DataFrames to PostgreSQL tables\n",
    "connection_string = f\"postgresql://{db_params['user']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['dbname']}\"\n",
    "\n",
    "try:\n",
    "    ticker_rows = upload_df_to_table(connection_string, 'ticker_tb', ticker_df)\n",
    "    print(f\"Data for ticker_tb uploaded successfully. Total rows: {ticker_rows}\")\n",
    "    \n",
    "    sp500_rows = upload_df_to_table(connection_string, 'sp500_tb', cleaned_df)\n",
    "    print(f\"Data for sp500_tb uploaded successfully. Total rows: {sp500_rows}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Add fake data to portfolio_tb\n",
    "# Create a DataFrame with specific ticker symbols\n",
    "portfolio_data = {\n",
    "    'ticker': ['AAPL', 'NVDA', 'AMZN', 'TSLA', 'NFLX', 'MCD'],\n",
    "    'shares': [50, 30, 40, 25, 35, 45]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "portfolio_df = pd.DataFrame(portfolio_data)\n",
    "\n",
    "# Upload the DataFrame to PostgreSQL\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    portfolio_df.to_sql('portfolio_tb', engine, if_exists='append', index=False)\n",
    "    print(f\"Data for portfolio_tb uploaded successfully. Total rows: {len(portfolio_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  distinct_date_count             min_date             max_date\n",
      "0        A                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "1      AAL                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "2      AAP                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "3     AAPL                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "4     ABBV                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "..     ...                  ...                  ...                  ...\n",
      "500    XYL                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "501    YUM                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "502    ZBH                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "503   ZION                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "504    ZTS                 1259  2013-02-08 00:00:00  2018-02-07 00:00:00\n",
      "\n",
      "[505 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "result = cleaned_df.groupby('ticker').agg(\n",
    "    distinct_date_count=('date', 'nunique'),\n",
    "    min_date=('date', 'min'),\n",
    "    max_date=('date', 'max')\n",
    ").reset_index()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly.graph_objects as go  \n",
    "\n",
    "\n",
    "# # Set the style for the plots\n",
    "# sns.set(style=\"darkgrid\")\n",
    "\n",
    "# # Function to plot historical price trends, volatility, moving averages, etc., for a given ticker\n",
    "# def plot_stock_analysis(ticker):\n",
    "#     # Load stock data for the selected ticker\n",
    "#     stock_data = cleaned_df[cleaned_df['ticker'] == ticker]\n",
    "    \n",
    "#     if stock_data.empty:\n",
    "#         print(f\"No data found for ticker: {ticker}\")\n",
    "#         return\n",
    "\n",
    "#     # Ensure the data is sorted by date\n",
    "#     stock_data = stock_data.sort_values(by='date')\n",
    "    \n",
    "#     # Calculate daily returns\n",
    "#     stock_data['daily_return'] = stock_data['close_price'].pct_change()\n",
    "\n",
    "#     # Historical Price Trends show the overall price movement.\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(stock_data['date'], stock_data['close_price'], label='Closing Price', color='b', alpha=0.7)\n",
    "#     plt.title(f\"Historical Price Trends for {ticker}\")\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Price (USD)')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # RSI (Relative Strength Index) shows the stock’s potential overbought/oversold condition.\n",
    "#     def compute_rsi(data, window=14):\n",
    "#         delta = data.diff()\n",
    "#         gain = delta.where(delta > 0, 0)\n",
    "#         loss = -delta.where(delta < 0, 0)\n",
    "#         avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "#         avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "#         rs = avg_gain / avg_loss\n",
    "#         rsi = 100 - (100 / (1 + rs))\n",
    "#         return rsi\n",
    "\n",
    "#     stock_data['RSI'] = compute_rsi(stock_data['close_price'])\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(stock_data['date'], stock_data['RSI'], label='RSI', color='purple')\n",
    "#     plt.axhline(30, color='red', linestyle='--')\n",
    "#     plt.axhline(70, color='green', linestyle='--')\n",
    "#     plt.title(f\"RSI for {ticker}\")\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('RSI')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # Bollinger Bands provide a measure of volatility and potential overbought/oversold signals.\n",
    "#     rolling_mean = stock_data['close_price'].rolling(window=20).mean()\n",
    "#     rolling_std = stock_data['close_price'].rolling(window=20).std()\n",
    "#     stock_data['Bollinger_Upper'] = rolling_mean + (rolling_std * 2)\n",
    "#     stock_data['Bollinger_Lower'] = rolling_mean - (rolling_std * 2)\n",
    "\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(stock_data['date'], stock_data['close_price'], label='Close Price', color='blue', alpha=0.7)\n",
    "#     plt.plot(stock_data['date'], stock_data['Bollinger_Upper'], label='Upper Band', color='red', linestyle='--')\n",
    "#     plt.plot(stock_data['date'], stock_data['Bollinger_Lower'], label='Lower Band', color='red', linestyle='--')\n",
    "#     plt.title(f\"Bollinger Bands for {ticker}\")\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Price (USD)')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "   \n",
    "\n",
    "#     # Drawdown Chart Using cumulative returns for drawdown\n",
    "#     stock_data['Cumulative_Returns'] = (1 + stock_data['daily_return']).cumprod()\n",
    "#     stock_data['Drawdown'] = stock_data['Cumulative_Returns'] - stock_data['Cumulative_Returns'].cummax()\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.fill_between(stock_data['date'], stock_data['Drawdown'], color='red', alpha=0.6)\n",
    "#     plt.title(f\"Drawdown for {ticker}\")\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Drawdown')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    " \n",
    "\n",
    "# # Example usage: Allow the user to input/select the ticker\n",
    "# ticker_input = input(\"Enter a ticker symbol (e.g., AAPL, MSFT, NFXL): \").upper()  # Convert input to uppercase\n",
    "# plot_stock_analysis(ticker_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical Price Trends (Closing Price)\n",
    "What it shows: This plot shows how the stock’s closing price has changed over time.\n",
    "Why it’s useful: The historical price trend helps investors to visualize the long-term price movement of a stock. It can indicate trends, peaks, and dips over a period of time.\n",
    "How it's calculated: The plot simply takes the Close_Price of the stock and plots it against the Date. This is the most basic way to track the stock's performance over time.\n",
    "\n",
    "Relative Strength Index (RSI)\n",
    "What it shows: The RSI is a momentum oscillator that measures the speed and change of price movements. It helps determine whether a stock is overbought or oversold.\n",
    "Why it’s useful: An RSI above 70 typically indicates that the stock is overbought (potentially overvalued), and an RSI below 30 suggests that the stock is oversold (potentially undervalued). It is used to identify potential buy and sell signals.\n",
    "How it's calculated: The RSI is calculated using the average gain and loss over a 14-day period. It is plotted on a scale of 0 to 100. If the RSI is above 70, the stock is considered overbought; if it’s below 30, the stock is considered oversold.\n",
    "\n",
    "Bollinger Bands\n",
    "What it shows: Bollinger Bands are volatility bands placed above and below a moving average. The distance between the bands increases or decreases based on volatility.\n",
    "Why it’s useful: The upper and lower bands provide insights into the overbought or oversold conditions of the stock. When the price reaches the upper band, the stock may be considered overbought, and when it reaches the lower band, it may be considered oversold.\n",
    "How it's calculated:\n",
    "The Middle Band is the 20-period simple moving average (SMA) of the closing prices.\n",
    "The Upper Band is the 20-period SMA plus two times the standard deviation of the closing prices.\n",
    "The Lower Band is the 20-period SMA minus two times the standard deviation of the closing prices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
